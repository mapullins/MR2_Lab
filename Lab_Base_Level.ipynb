{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem addressed here concerns the 1999 Playstation video game Monster Rancher 2. In the video game, players breed and battle monsters, which have a main type, a sub type, and stats such as Life, Power, Intelligence, Skill, Speed, and Defense (Lif, Pow, Int, Ski, Spd, Def for short), as well as other data. There is an in-game mechanic where players are able to combine monsters to get a new monster, which we'll refer to as the offspring or the result. This is done at the Lab. \n",
    "\n",
    "The mechanics of the Lab are mostly uncovered, except for occasional weird exceptions. An in-depth explanation of the lab mechanics can be found at https://gamefaqs.gamespot.com/ps/197977-monster-rancher-2/faqs/41787. In brief, monster stats are multiplied by a growth factor for each respective stat based on main and sub monster type. According to the guide, the product is capped at $999$. However, I had more luck with my calculations if there is no cap. These products are ordered from highest to lowest, with the base stats being used to break any ties. The number of matches in the order determine what Dadge, the character running the lab, says. For some reason, my game appears to differ from the guide. My order appears to be\n",
    "\n",
    "* 0 stats = Up to You\n",
    "* 1 stat = Not Good\n",
    "* 2 stats = Unsure\n",
    "* 3 stats = Fine\n",
    "* 4 stats = Good\n",
    "* 6 stats = Great\n",
    "\n",
    "If the order of the stats match (and the order of the offspring stat also matches), then a stat boost is given to the offspring and the amount of boost is partially determined by a random number generator (seen in the data itself). This is not the case we are concerned with here.\n",
    "\n",
    "This notebook's aim is less practical towards optimal game-play. I've noticed that if the monsters used to create the offspring do not match in a stat's position, then when the offspring is the same, the stat number is the same. This indicates that there is an underlying formula that determines the offspring's stat, and then stat boosts are added if applicable. Instead of finding the optimal way to combine monsters, which has already been done, our aim is to first uncover the underlying formula when stats do not match.\n",
    "\n",
    "Here is a brief outline of how this will be handled. I have compiled data from near 700 combinations done at the lab, recording vital statistics that could be involved. The collection of these can be read in the documentation of the data files. I believe that the same formula governs all stats, so we will develop the formula using only data from the Lif stat. Once the formula is found, the test data will be the other five stats: Pow, Int, Ski, Spd, and Def.\n",
    "\n",
    "Note that we exclude any parents whose stat order matches in a particular stat. This is being extra cautious to avoid the weird exceptions mentioned above where the stat order calculation doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Graphs\n",
    "import matplotlib as mlt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few columns that we need, but were not thought of until after the data was collected. Duplicates are eliminated and more columns are created by combining some preexisting columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main_Stat</th>\n",
       "      <th>Main_Growth</th>\n",
       "      <th>Main_Base</th>\n",
       "      <th>Main_Base_Rank</th>\n",
       "      <th>Main_True_Rank</th>\n",
       "      <th>Sub_Stat</th>\n",
       "      <th>Sub_Growth</th>\n",
       "      <th>Sub_Base</th>\n",
       "      <th>Sub_Base_Rank</th>\n",
       "      <th>Sub_True_Rank</th>\n",
       "      <th>...</th>\n",
       "      <th>Result_Growth</th>\n",
       "      <th>Result_Base</th>\n",
       "      <th>Result_Base_Rank</th>\n",
       "      <th>Result_True_Rank</th>\n",
       "      <th>Main_Result</th>\n",
       "      <th>Sub_Result</th>\n",
       "      <th>Type</th>\n",
       "      <th>Main</th>\n",
       "      <th>Sub</th>\n",
       "      <th>Rarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Good</td>\n",
       "      <td>Cpandora</td>\n",
       "      <td>Cpandora</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Good</td>\n",
       "      <td>Durahan</td>\n",
       "      <td>Joker</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Good</td>\n",
       "      <td>Joker</td>\n",
       "      <td>Joker</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Good</td>\n",
       "      <td>Durahan</td>\n",
       "      <td>Durahan</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Good</td>\n",
       "      <td>Durahan</td>\n",
       "      <td>Joker</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Main_Stat  Main_Growth  Main_Base  Main_Base_Rank  Main_True_Rank  \\\n",
       "0        999            5        170               1               1   \n",
       "2        999            5        170               1               1   \n",
       "3        999            5        170               1               1   \n",
       "7        999            3        100               5               5   \n",
       "8        999            3        100               5               5   \n",
       "\n",
       "   Sub_Stat  Sub_Growth  Sub_Base  Sub_Base_Rank  Sub_True_Rank  ...  \\\n",
       "0       999           3       100              5              5  ...   \n",
       "2       999           3       100              5              5  ...   \n",
       "3       999           3       100              5              5  ...   \n",
       "7       999           5       170              1              1  ...   \n",
       "8       999           5       170              1              1  ...   \n",
       "\n",
       "   Result_Growth  Result_Base  Result_Base_Rank  Result_True_Rank  \\\n",
       "0              5          170                 1                 1   \n",
       "2              3          100                 5                 5   \n",
       "3              3          120                 3                 4   \n",
       "7              3          100                 4                 4   \n",
       "8              3          100                 5                 5   \n",
       "\n",
       "   Main_Result  Sub_Result      Type      Main       Sub Rarity  \n",
       "0            1           0  Not Good  Cpandora  Cpandora     38  \n",
       "2            0           1  Not Good   Durahan     Joker     29  \n",
       "3            0           0  Not Good     Joker     Joker     12  \n",
       "7            0           0  Not Good   Durahan   Durahan     21  \n",
       "8            1           0  Not Good   Durahan     Joker     48  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data for the in-game Lif stat\n",
    "df_lif = pd.read_csv('Lif_Data_1.csv')\n",
    "\n",
    "#Drop duplicate rows\n",
    "df_lif.drop_duplicates(inplace = True)\n",
    "df_lif.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for rarity levels\n",
    "def rarity_levels(num):\n",
    "    if num <= 3:\n",
    "        return 1\n",
    "    elif num <= 7:\n",
    "        return 2\n",
    "    elif num <= 14:\n",
    "        return 3\n",
    "    elif num <= 29:\n",
    "        return 4\n",
    "    elif num <= 49:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "    \n",
    "#Function to check if a random number is added to the stat  \n",
    "def boost_check(row):\n",
    "    if (row['Main_True_Rank'] == row['Sub_True_Rank']):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Creates the extra columns needed to do the analysis\n",
    "def add_columns(df, no_randoms = True):\n",
    "    \n",
    "    #Calculates differences from base stats\n",
    "    df['Result_Dif'] = df['Result_Stat'] - df['Result_Base']\n",
    "    df['Main_Dif'] = df['Main_Stat'] - df['Main_Base']\n",
    "    df['Sub_Dif'] = df['Sub_Stat'] - df['Sub_Base']\n",
    "    \n",
    "    #Transforms rarity into categorical data\n",
    "    df['Rarity_Level'] = df.Rarity.apply(rarity_levels)\n",
    "    \n",
    "    #Create feature to track if random number is added\n",
    "    df['Boost'] = df.apply(boost_check, axis = 1)\n",
    "    \n",
    "    #Drop features that were used in calculating the difference features\n",
    "    df.drop(columns = ['Result_Stat', 'Result_Base', 'Main_Stat', 'Main_Base', 'Sub_Stat', 'Sub_Base'], inplace = True)\n",
    "    \n",
    "    if no_randoms == True:\n",
    "        return df[df.Boost == 0]\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add additional columns to DataFrame\n",
    "df_lif = add_columns(df_lif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rarity_Level feature is worth explaining here. Below are five samples from the dataframe with the same parents, and five different children. The least rare, the Dragon/Kato gets $60$ added to its base Lif. From there, the amount added increases by $12$ as the Rarity_Level becomes smaller.\n",
    "\n",
    "The next sample demonstrates how the Rarity feature needs to be a step function. Observe that $9$ and $14$ both result in $70$ being added, while $22$ and $29$ both result in $60$ being added. Again, there is a linear decrease as the Rarity_Level increases. The slope of the decrease appears linked to other features as well, an early clue that there is feature interaction. It should be noted that although in these examples the decrease is linear, that should not be assumed to always be the case.\n",
    "\n",
    "There is sufficient data to create most of the Rarity_Levels seen in the Rarity_Level feature. However, higher cut-offs were determined without solid evidence. These were selected based on educated guesses (and the changes improved the results). Since the Rarity feature is really a percentage, then it's unusual to see both a number in the $40$s and a number in the $30$s in a single combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main_Growth</th>\n",
       "      <th>Main_Base_Rank</th>\n",
       "      <th>Main_True_Rank</th>\n",
       "      <th>Sub_Growth</th>\n",
       "      <th>Sub_Base_Rank</th>\n",
       "      <th>Sub_True_Rank</th>\n",
       "      <th>Result_Growth</th>\n",
       "      <th>Result_Base_Rank</th>\n",
       "      <th>Result_True_Rank</th>\n",
       "      <th>Main_Result</th>\n",
       "      <th>Sub_Result</th>\n",
       "      <th>Type</th>\n",
       "      <th>Main</th>\n",
       "      <th>Sub</th>\n",
       "      <th>Rarity</th>\n",
       "      <th>Result_Dif</th>\n",
       "      <th>Main_Dif</th>\n",
       "      <th>Sub_Dif</th>\n",
       "      <th>Rarity_Level</th>\n",
       "      <th>Boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Up to You</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Golem</td>\n",
       "      <td>16</td>\n",
       "      <td>72</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Up to You</td>\n",
       "      <td>Kato</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Up to You</td>\n",
       "      <td>Kato</td>\n",
       "      <td>Gali</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Up to You</td>\n",
       "      <td>Golem</td>\n",
       "      <td>Gali</td>\n",
       "      <td>12</td>\n",
       "      <td>84</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Up to You</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Kato</td>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Main_Growth  Main_Base_Rank  Main_True_Rank  Sub_Growth  Sub_Base_Rank  \\\n",
       "667            3               4               4           2              5   \n",
       "668            3               4               4           2              5   \n",
       "669            3               4               4           2              5   \n",
       "670            3               4               4           2              5   \n",
       "671            3               4               4           2              5   \n",
       "\n",
       "     Sub_True_Rank  Result_Growth  Result_Base_Rank  Result_True_Rank  \\\n",
       "667              5              3                 4                 4   \n",
       "668              5              2                 6                 6   \n",
       "669              5              2                 5                 5   \n",
       "670              5              3                 4                 4   \n",
       "671              5              3                 6                 6   \n",
       "\n",
       "     Main_Result  Sub_Result       Type    Main     Sub  Rarity  Result_Dif  \\\n",
       "667            1           0  Up to You  Dragon   Golem      16          72   \n",
       "668            0           0  Up to You    Kato  Dragon       5          96   \n",
       "669            0           1  Up to You    Kato    Gali       2         108   \n",
       "670            0           0  Up to You   Golem    Gali      12          84   \n",
       "671            0           0  Up to You  Dragon    Kato      33          60   \n",
       "\n",
       "     Main_Dif  Sub_Dif  Rarity_Level  Boost  \n",
       "667       800      800             4      0  \n",
       "668       800      800             2      0  \n",
       "669       800      800             1      0  \n",
       "670       800      800             3      0  \n",
       "671       800      800             5      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lif.iloc[502:507]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main_Growth</th>\n",
       "      <th>Main_Base_Rank</th>\n",
       "      <th>Main_True_Rank</th>\n",
       "      <th>Sub_Growth</th>\n",
       "      <th>Sub_Base_Rank</th>\n",
       "      <th>Sub_True_Rank</th>\n",
       "      <th>Result_Growth</th>\n",
       "      <th>Result_Base_Rank</th>\n",
       "      <th>Result_True_Rank</th>\n",
       "      <th>Main_Result</th>\n",
       "      <th>Sub_Result</th>\n",
       "      <th>Type</th>\n",
       "      <th>Main</th>\n",
       "      <th>Sub</th>\n",
       "      <th>Rarity</th>\n",
       "      <th>Result_Dif</th>\n",
       "      <th>Main_Dif</th>\n",
       "      <th>Sub_Dif</th>\n",
       "      <th>Rarity_Level</th>\n",
       "      <th>Boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Up to You</td>\n",
       "      <td>Plant</td>\n",
       "      <td>Zuum</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>586</td>\n",
       "      <td>839</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Up to You</td>\n",
       "      <td>Monol</td>\n",
       "      <td>Plant</td>\n",
       "      <td>28</td>\n",
       "      <td>60</td>\n",
       "      <td>586</td>\n",
       "      <td>839</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Up to You</td>\n",
       "      <td>Zuum</td>\n",
       "      <td>Plant</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>586</td>\n",
       "      <td>839</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Up to You</td>\n",
       "      <td>Plant</td>\n",
       "      <td>Monol</td>\n",
       "      <td>14</td>\n",
       "      <td>70</td>\n",
       "      <td>586</td>\n",
       "      <td>839</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Up to You</td>\n",
       "      <td>Monol</td>\n",
       "      <td>Zuum</td>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>586</td>\n",
       "      <td>839</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Main_Growth  Main_Base_Rank  Main_True_Rank  Sub_Growth  Sub_Base_Rank  \\\n",
       "493            2               5               5           5              1   \n",
       "494            2               5               5           5              1   \n",
       "495            2               5               5           5              1   \n",
       "496            2               5               5           5              1   \n",
       "497            2               5               5           5              1   \n",
       "\n",
       "     Sub_True_Rank  Result_Growth  Result_Base_Rank  Result_True_Rank  \\\n",
       "493              1              4                 1                 1   \n",
       "494              1              3                 3                 3   \n",
       "495              1              4                 2                 1   \n",
       "496              1              4                 1                 1   \n",
       "497              1              2                 5                 5   \n",
       "\n",
       "     Main_Result  Sub_Result       Type   Main    Sub  Rarity  Result_Dif  \\\n",
       "493            0           0  Up to You  Plant   Zuum       7          80   \n",
       "494            0           0  Up to You  Monol  Plant      28          60   \n",
       "495            0           0  Up to You   Zuum  Plant      22          60   \n",
       "496            0           0  Up to You  Plant  Monol      14          70   \n",
       "497            1           0  Up to You  Monol   Zuum       9          70   \n",
       "\n",
       "     Main_Dif  Sub_Dif  Rarity_Level  Boost  \n",
       "493       586      839             2      0  \n",
       "494       586      839             4      0  \n",
       "495       586      839             4      0  \n",
       "496       586      839             3      0  \n",
       "497       586      839             3      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lif.loc[493:497]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - The Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the goal is to discover a formula for a video game, there are a few safe assumptions that can be made. First, the formula was written by humans, so the numbers should be relatively nice and the formula itself should not be too complicated. For this reason, it is very likely the formula is based on a linear model. Second, it is unlikely that the formula will involve a ton of the features included. This is another result of the formula being written by humans.\n",
    "\n",
    "To discover the best variables, Lasso is used with varying degress of regularization. This gives a starting point for which variables are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe to look at changing coefficients\n",
    "def coef_change(X_train, y_train, X_val, y_val, col, alphas):\n",
    "    \n",
    "    #Add an error columns to the columns\n",
    "    true_col = list(col)\n",
    "    true_col.append('Error')\n",
    "    \n",
    "    #Create a blank dataframe to fill with coefficients\n",
    "    df_coef = pd.DataFrame([], columns = true_col)\n",
    "    \n",
    "    #Loop through the alphas, use Lasso to get coefficients and error, then populate df_coef\n",
    "    for a in alphas:\n",
    "        model = Lasso(alpha = a, max_iter = 10000).fit(X_train, y_train)\n",
    "        err = np.sqrt(mean_squared_error(y_val,  model.predict(X_val)))\n",
    "        row = list(model.coef_)\n",
    "        row.append(err)\n",
    "        df_coef.loc[a] = row\n",
    "        \n",
    "    #Graph the error\n",
    "    fig, ax = plt.subplots(figsize = (7,4))\n",
    "    ax.plot(alphas, df_coef.Error);\n",
    "    plt.title('Root Mean Squared Error by Alpha in Lasso')\n",
    "    plt.xlabel('Lasso')\n",
    "    plt.ylabel('Root Mean Squared Error')\n",
    "    \n",
    "    #Return DataFrame\n",
    "    return df_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main_Growth</th>\n",
       "      <th>Main_Base_Rank</th>\n",
       "      <th>Main_True_Rank</th>\n",
       "      <th>Sub_Growth</th>\n",
       "      <th>Sub_Base_Rank</th>\n",
       "      <th>Sub_True_Rank</th>\n",
       "      <th>Result_Growth</th>\n",
       "      <th>Result_Base_Rank</th>\n",
       "      <th>Result_True_Rank</th>\n",
       "      <th>Main_Result</th>\n",
       "      <th>Sub_Result</th>\n",
       "      <th>Rarity</th>\n",
       "      <th>Main_Dif</th>\n",
       "      <th>Sub_Dif</th>\n",
       "      <th>Rarity_Level</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.327407</td>\n",
       "      <td>-0.398504</td>\n",
       "      <td>0.294166</td>\n",
       "      <td>-0.002128</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.511844</td>\n",
       "      <td>-0.120514</td>\n",
       "      <td>0.685257</td>\n",
       "      <td>-0.130048</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.094738</td>\n",
       "      <td>-0.066478</td>\n",
       "      <td>13.214153</td>\n",
       "      <td>8.199102</td>\n",
       "      <td>-11.347976</td>\n",
       "      <td>3.113679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.214645</td>\n",
       "      <td>-0.024002</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003214</td>\n",
       "      <td>-0.353811</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.461907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.016934</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>13.158166</td>\n",
       "      <td>8.185553</td>\n",
       "      <td>-11.334224</td>\n",
       "      <td>3.057276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>12.379305</td>\n",
       "      <td>7.476218</td>\n",
       "      <td>-10.400614</td>\n",
       "      <td>3.456924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>9.192398</td>\n",
       "      <td>3.941429</td>\n",
       "      <td>-6.172417</td>\n",
       "      <td>8.331058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>5.098684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.917609</td>\n",
       "      <td>15.487415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.00</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>19.508340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Main_Growth  Main_Base_Rank  Main_True_Rank  Sub_Growth  Sub_Base_Rank  \\\n",
       "0.01      0.327407       -0.398504        0.294166   -0.002128      -0.000000   \n",
       "0.10      0.214645       -0.024002       -0.000000    0.000000      -0.003214   \n",
       "1.00      0.000000       -0.000000        0.000000    0.000000      -0.000000   \n",
       "5.00      0.000000       -0.000000        0.000000    0.000000      -0.000000   \n",
       "10.00     0.000000       -0.000000        0.000000    0.000000      -0.000000   \n",
       "20.00    -0.000000       -0.000000        0.000000    0.000000      -0.000000   \n",
       "\n",
       "       Sub_True_Rank  Result_Growth  Result_Base_Rank  Result_True_Rank  \\\n",
       "0.01       -0.511844      -0.120514          0.685257         -0.130048   \n",
       "0.10       -0.353811      -0.000000          0.461907          0.000000   \n",
       "1.00       -0.000000      -0.000000          0.000000          0.000000   \n",
       "5.00       -0.000000      -0.000000          0.000000          0.000000   \n",
       "10.00      -0.000000      -0.000000         -0.000000          0.000000   \n",
       "20.00      -0.000000      -0.000000         -0.000000          0.000000   \n",
       "\n",
       "       Main_Result  Sub_Result    Rarity   Main_Dif   Sub_Dif  Rarity_Level  \\\n",
       "0.01      0.016799    0.094738 -0.066478  13.214153  8.199102    -11.347976   \n",
       "0.10     -0.000000    0.016934 -0.000000  13.158166  8.185553    -11.334224   \n",
       "1.00     -0.000000    0.000000 -0.000000  12.379305  7.476218    -10.400614   \n",
       "5.00     -0.000000    0.000000 -0.000000   9.192398  3.941429     -6.172417   \n",
       "10.00    -0.000000    0.000000 -0.000000   5.098684  0.000000     -0.917609   \n",
       "20.00    -0.000000    0.000000 -0.000000   0.000000  0.000000     -0.000000   \n",
       "\n",
       "           Error  \n",
       "0.01    3.113679  \n",
       "0.10    3.057276  \n",
       "1.00    3.456924  \n",
       "5.00    8.331058  \n",
       "10.00  15.487415  \n",
       "20.00  19.508340  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Want to predict number added to base\n",
    "y = df_lif.Result_Dif\n",
    "\n",
    "#X is everything but Result_Dif, Type, Main, Sub, and Boost\n",
    "X = df_lif.drop(columns = ['Result_Dif', 'Type', 'Main', 'Sub', 'Boost'])\n",
    "\n",
    "#Split into training set and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, train_size = .8, random_state = 0)\n",
    "\n",
    "#Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "df_coef = coef_change(X_train_scale, y_train, X_val_scale, y_val, X.columns, [.01, .1, 1, 5, 10, 20])\n",
    "df_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the dataframe, it appears that the only features that make a significant difference are Main_Dif, Sub_Dif, and Rarity_Level. When looking at ways to improve the prediction, these features will serve as the base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Polynomial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests different degrees of polynomial features on a linear model, then displays error as a graph\n",
    "def poly_plot(X_train, y_train, X_val, y_val, degree):\n",
    "    \n",
    "    #Creates the list of degrees to try and an empty list for errors\n",
    "    degree_list = list(range(1, degree + 1))\n",
    "    error_list = []\n",
    "    \n",
    "    #Loop through each degree\n",
    "    for deg in degree_list:\n",
    "        \n",
    "        #Create and fits the polynomial features\n",
    "        poly = PolynomialFeatures(deg)\n",
    "        X_train_p = poly.fit_transform(X_train)\n",
    "        X_val_p = poly.transform(X_val)\n",
    "        \n",
    "        poly_model = LinearRegression().fit(X_train_p, y_train)\n",
    "        error_list.append(np.sqrt(mean_squared_error(y_val, poly_model.predict(X_val_p))))\n",
    "        \n",
    "    #Graph the errors\n",
    "    fig, ax = plt.subplots(figsize = (7,4))\n",
    "    ax.plot(degree_list, error_list);\n",
    "    plt.title('Root Mean Squared Error by Polynomial Degree')\n",
    "    plt.xlabel('Polynomial Degree')\n",
    "    plt.ylabel('Root Mean Squared Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#List features to use\n",
    "features = ['Main_Dif', 'Sub_Dif', 'Rarity_Level']\n",
    "\n",
    "#Features and split into same training and validation sets\n",
    "y = df_lif.Result_Dif\n",
    "X = df_lif[features]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, train_size = .8, random_state = 0)\n",
    "\n",
    "\n",
    "poly_plot(X_train, y_train, X_val, y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square of the mean squared error for the degree two polynomial model is 0.35254144898599143\n",
      "Intercept: 0.0\n",
      "Main_Dif: 20.460238391891274\n",
      "Sub_Dif: 12.00650571363536\n",
      "Rarity_Level: -0.13830410111796088\n",
      "Main_Dif Squared: -0.24917088434697465\n",
      "Main_Dif * Sub_Dif: 0.030374615319779252\n",
      "Main_Dif * Rarity_Level: -10.755887375385914\n",
      "Sub_Dif Squared: 0.24967655054895843\n",
      "Sub_Dif * Rarity_Level: -5.872949170495219\n",
      "Rarity_Level Squared: 0.20738177019403325\n"
     ]
    }
   ],
   "source": [
    "#Create polynomial features\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_p = poly.fit_transform(X_train)\n",
    "X_val_p = poly.transform(X_val)\n",
    "\n",
    "#Scale the polynomial features\n",
    "scaler = StandardScaler()\n",
    "X_train_ps = scaler.fit_transform(X_train_p)\n",
    "X_val_ps = scaler.transform(X_val_p)\n",
    "\n",
    "#Create and fit model\n",
    "poly_model = LinearRegression().fit(X_train_ps, y_train)\n",
    "\n",
    "#List of the coefficient meanings\n",
    "coefs = ['Intercept', 'Main_Dif', 'Sub_Dif', 'Rarity_Level', 'Main_Dif Squared', 'Main_Dif * Sub_Dif', \\\n",
    "        'Main_Dif * Rarity_Level', 'Sub_Dif Squared', 'Sub_Dif * Rarity_Level', 'Rarity_Level Squared']\n",
    "model_coef = list(poly_model.coef_)\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y_val, poly_model.predict(X_val_ps)))\n",
    "print('The square of the mean squared error for the degree two polynomial model is {0}'.format(error))\n",
    "\n",
    "#Print the coefficients\n",
    "for i in range(len(coefs)):\n",
    "    print('{0}: {1}'.format(coefs[i], model_coef[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we scaled the features, the coefficients above can help indicate which polynomial features are actually contributing. Main_Dif and Sub_Dif are important, and their products with Rarity_Level appear important as well due to the large coefficients. \n",
    "\n",
    "Because there is an underlying formula written by humans, the next step will be to perform the same model fit without scaling, then look at the coefficients of Main_Dif, Sub_Dif, Main_Dif Times Rarity_Level, and Sub_Dif Times Rarity_level. They should be close to nice numbers that a human writing a mathematical formula would use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square of the mean squared error for the degree two polynomial model is 0.3525414489859511\n",
      "Intercept: 0.0\n",
      "Main_Dif: 0.10096702772752958\n",
      "Sub_Dif: 0.04901000235561237\n",
      "Rarity_Level: -0.13171822290825247\n",
      "Main_Dif Squared: -9.818601100844426e-07\n",
      "Main_Dif * Sub_Dif: 1.1832829704960801e-07\n",
      "Main_Dif * Rarity_Level: -0.009940152362961904\n",
      "Sub_Dif Squared: 8.521725444396444e-07\n",
      "Sub_Dif * Rarity_Level: -0.005012163014664891\n",
      "Rarity_Level Squared: 0.02871868453779217\n"
     ]
    }
   ],
   "source": [
    "#Create polynomial features\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_p = poly.fit_transform(X_train)\n",
    "X_val_p = poly.transform(X_val)\n",
    "\n",
    "#Create and fit model\n",
    "poly_model = LinearRegression().fit(X_train_p, y_train)\n",
    "\n",
    "#List of the coefficient meanings\n",
    "coefs = ['Intercept', 'Main_Dif', 'Sub_Dif', 'Rarity_Level', 'Main_Dif Squared', 'Main_Dif * Sub_Dif', \\\n",
    "        'Main_Dif * Rarity_Level', 'Sub_Dif Squared', 'Sub_Dif * Rarity_Level', 'Rarity_Level Squared']\n",
    "model_coef = list(poly_model.coef_)\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y_val, poly_model.predict(X_val_p)))\n",
    "print('The square of the mean squared error for the degree two polynomial model is {0}'.format(error))\n",
    "\n",
    "#Print the coefficients\n",
    "for i in range(len(coefs)):\n",
    "    print('{0}: {1}'.format(coefs[i], model_coef[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the coefficients we want are very close to fairly simple fractions. Here they are listed below\n",
    "\n",
    "* Main_Dif = $\\frac{1}{10}$\n",
    "* Sub_Dif = $\\frac{1}{20}$\n",
    "* Main_Dif*Rarity_Level = $\\frac{1}{100}$\n",
    "* Main_Dif*Rarity_Level = $\\frac{1}{200}$\n",
    "\n",
    "If we take the coefficient of Rarity_Level to be $\\frac{1}{10}$ then the formula can be written quite simply as\n",
    "\n",
    "$$\\text{Offspring_Stat_Gain} = \\left(\\frac{\\text{Main_Dif}}{10} + \\frac{\\text{Sub_Dif}}{20}\\right) \\left(1 - \\frac{\\text{Rarity_Level}}{10}  \\right).  $$\n",
    "\n",
    "In the next cell, floor functions are used to make this more accurate. This was determined experimentally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General formula for offspring stat boost\n",
    "def offspring_formula(row):\n",
    "    #Get features from row\n",
    "    Main_Dif = row['Main_Dif']\n",
    "    Sub_Dif = row['Sub_Dif']\n",
    "    Rarity_Level = row['Rarity_Level']\n",
    "    \n",
    "    #Formula\n",
    "    f = int(Main_Dif/10 + Sub_Dif/20)\n",
    "    return int(f * (1-  Rarity_Level/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2013468165642073"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y, X.apply(offspring_formula, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 34, Predicted_Value: 35, Difference = 1\n",
      "True Value: 60, Predicted_Value: 61, Difference = 1\n",
      "True Value: 28, Predicted_Value: 29, Difference = 1\n",
      "True Value: 39, Predicted_Value: 40, Difference = 1\n",
      "True Value: 45, Predicted_Value: 46, Difference = 1\n",
      "True Value: 28, Predicted_Value: 29, Difference = 1\n",
      "True Value: 45, Predicted_Value: 46, Difference = 1\n",
      "True Value: 52, Predicted_Value: 53, Difference = 1\n",
      "True Value: 52, Predicted_Value: 53, Difference = 1\n",
      "True Value: 61, Predicted_Value: 62, Difference = 1\n",
      "True Value: 76, Predicted_Value: 77, Difference = 1\n",
      "True Value: 87, Predicted_Value: 88, Difference = 1\n",
      "True Value: 76, Predicted_Value: 77, Difference = 1\n",
      "True Value: 65, Predicted_Value: 66, Difference = 1\n",
      "True Value: 76, Predicted_Value: 77, Difference = 1\n",
      "True Value: 65, Predicted_Value: 66, Difference = 1\n",
      "True Value: 76, Predicted_Value: 77, Difference = 1\n",
      "True Value: 65, Predicted_Value: 66, Difference = 1\n",
      "True Value: 43, Predicted_Value: 44, Difference = 1\n",
      "True Value: 36, Predicted_Value: 37, Difference = 1\n",
      "True Value: 65, Predicted_Value: 66, Difference = 1\n"
     ]
    }
   ],
   "source": [
    "#Check which entries the formula did not guess exactly\n",
    "predictions = X.apply(offspring_formula, axis = 1)\n",
    "ind = 0\n",
    "for entry in y:\n",
    "    if entry != predictions.iloc[ind]:\n",
    "        print('True Value: {0}, Predicted_Value: {1}, Difference = {2}'.format(entry, predictions.iloc[ind], predictions.iloc[ind] - entry))\n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that there are only $21$ mistakes, and that all of these mistakes are off by only $1$ gives strong evidence that the formula chosen is the correct one.\n",
    "\n",
    "Although the formula does not appear to always be correct, its proximity to the correct answer hints that the only difference is either errors in collection of the data or rounding errors. Since rounding is used in the formula itself, it could be that the true formula round at different places or has different rules on rounding.\n",
    "\n",
    "Rounding errors here don't amount to a large change, so this is considered the \"true formula\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Other Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous sections, only data from the Lif stat was used. Now, the data from the remaining five statistics will be combined and used to see if the general formula is accurate across these too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the other five .csv files\n",
    "df_pow = pd.read_csv('Pow_Data_1.csv')\n",
    "df_int = pd.read_csv('Int_Data_1.csv')\n",
    "df_ski = pd.read_csv('Ski_Data_1.csv')\n",
    "df_spd = pd.read_csv('Spd_Data_1.csv')\n",
    "df_def = pd.read_csv('Def_Data_1.csv')\n",
    "\n",
    "#Combine into a single DataFrame and eliminate duplicates\n",
    "df_test = pd.concat([df_pow, df_int, df_ski, df_spd, df_def])\n",
    "df_test.drop_duplicates(inplace = True)\n",
    "\n",
    "#Add extra columns\n",
    "df_test = add_columns(df_test)\n",
    "\n",
    "#Select features\n",
    "features = ['Main_Dif', 'Sub_Dif', 'Rarity_Level']\n",
    "y_test = df_test.Result_Dif\n",
    "X_test = df_test[features]\n",
    "\n",
    "#Create polynomial versions\n",
    "X_test_p = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Error = 0.3709056066598666 \n",
      "Formula Error = 0.16085155024444558\n"
     ]
    }
   ],
   "source": [
    "#Calculate mean squared error for the polynomial model and the predicted formula\n",
    "poly_error = np.sqrt(mean_squared_error(y_test, poly_model.predict(X_test_p)))\n",
    "formula_error = np.sqrt(mean_squared_error(y_test, X_test.apply(offspring_formula, axis = 1)))\n",
    "\n",
    "print('Polynomial Error = {0} \\nFormula Error = {1}'.format(poly_error, formula_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 46, Predicted_Value: 47, Difference = 1\n",
      "True Value: 46, Predicted_Value: 47, Difference = 1\n",
      "True Value: 53, Predicted_Value: 54, Difference = 1\n",
      "True Value: 53, Predicted_Value: 54, Difference = 1\n",
      "True Value: 60, Predicted_Value: 61, Difference = 1\n",
      "True Value: 46, Predicted_Value: 47, Difference = 1\n",
      "True Value: 60, Predicted_Value: 61, Difference = 1\n",
      "True Value: 60, Predicted_Value: 61, Difference = 1\n",
      "True Value: 84, Predicted_Value: 85, Difference = 1\n",
      "True Value: 63, Predicted_Value: 64, Difference = 1\n",
      "True Value: 63, Predicted_Value: 64, Difference = 1\n",
      "True Value: 57, Predicted_Value: 58, Difference = 1\n",
      "True Value: 76, Predicted_Value: 77, Difference = 1\n",
      "True Value: 38, Predicted_Value: 39, Difference = 1\n",
      "True Value: 38, Predicted_Value: 39, Difference = 1\n",
      "True Value: 38, Predicted_Value: 39, Difference = 1\n",
      "True Value: 39, Predicted_Value: 40, Difference = 1\n",
      "True Value: 39, Predicted_Value: 40, Difference = 1\n",
      "True Value: 59, Predicted_Value: 60, Difference = 1\n",
      "True Value: 39, Predicted_Value: 40, Difference = 1\n",
      "True Value: 52, Predicted_Value: 53, Difference = 1\n",
      "True Value: 39, Predicted_Value: 40, Difference = 1\n",
      "True Value: 39, Predicted_Value: 40, Difference = 1\n",
      "True Value: 4, Predicted_Value: 5, Difference = 1\n",
      "True Value: 3, Predicted_Value: 4, Difference = 1\n",
      "True Value: 63, Predicted_Value: 62, Difference = -1\n",
      "True Value: 63, Predicted_Value: 62, Difference = -1\n",
      "True Value: 38, Predicted_Value: 39, Difference = 1\n",
      "True Value: 57, Predicted_Value: 58, Difference = 1\n",
      "True Value: 44, Predicted_Value: 45, Difference = 1\n",
      "True Value: 55, Predicted_Value: 56, Difference = 1\n",
      "True Value: 47, Predicted_Value: 48, Difference = 1\n",
      "True Value: 55, Predicted_Value: 56, Difference = 1\n",
      "True Value: 63, Predicted_Value: 64, Difference = 1\n",
      "True Value: 43, Predicted_Value: 44, Difference = 1\n",
      "True Value: 76, Predicted_Value: 77, Difference = 1\n",
      "True Value: 72, Predicted_Value: 73, Difference = 1\n",
      "True Value: 84, Predicted_Value: 85, Difference = 1\n",
      "True Value: 72, Predicted_Value: 73, Difference = 1\n",
      "True Value: 72, Predicted_Value: 73, Difference = 1\n",
      "True Value: 96, Predicted_Value: 97, Difference = 1\n",
      "True Value: 56, Predicted_Value: 57, Difference = 1\n",
      "True Value: 48, Predicted_Value: 49, Difference = 1\n",
      "True Value: 48, Predicted_Value: 49, Difference = 1\n",
      "True Value: 56, Predicted_Value: 57, Difference = 1\n",
      "True Value: 48, Predicted_Value: 49, Difference = 1\n",
      "True Value: 59, Predicted_Value: 60, Difference = 1\n",
      "True Value: 59, Predicted_Value: 60, Difference = 1\n",
      "True Value: 52, Predicted_Value: 53, Difference = 1\n",
      "True Value: 52, Predicted_Value: 53, Difference = 1\n",
      "True Value: 75, Predicted_Value: 76, Difference = 1\n",
      "True Value: 86, Predicted_Value: 87, Difference = 1\n",
      "True Value: 75, Predicted_Value: 76, Difference = 1\n",
      "True Value: 64, Predicted_Value: 65, Difference = 1\n",
      "True Value: 75, Predicted_Value: 76, Difference = 1\n",
      "True Value: 64, Predicted_Value: 65, Difference = 1\n",
      "True Value: 75, Predicted_Value: 76, Difference = 1\n",
      "True Value: 64, Predicted_Value: 65, Difference = 1\n",
      "True Value: 55, Predicted_Value: 56, Difference = 1\n",
      "True Value: 74, Predicted_Value: 75, Difference = 1\n",
      "The number of mistakes is 60 out of 2319\n"
     ]
    }
   ],
   "source": [
    "#Check which entries the formula did not guess exactly\n",
    "predictions = X_test.apply(offspring_formula, axis = 1)\n",
    "ind = 0\n",
    "count = 0\n",
    "for entry in y_test:\n",
    "    if entry != predictions.iloc[ind]:\n",
    "        print('True Value: {0}, Predicted_Value: {1}, Difference = {2}'.format(entry, predictions.iloc[ind], predictions.iloc[ind] - entry))\n",
    "        count += 1\n",
    "    ind +=1\n",
    "print('The number of mistakes is {0} out of {1}'.format(count, X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $[]$ be the integer floor function. Then the formula used can be written as\n",
    "$$\\text{Offspring_Stat_Gain} = \\left[\\left[\\left(\\frac{\\text{Main_Dif}}{10} + \\frac{\\text{Sub_Dif}}{20}\\right)\\right] \\left(1 - \\frac{\\text{Rarity_Level}}{10}  \\right) \\right].  $$\n",
    "\n",
    "The only variable that doesn't come directly from the game is the Rarity_Level (so changing that will change the formula). The method we used to convert Rarity into Rarity_Level is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rarity</th>\n",
       "      <th>Rarity_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 - 3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 - 7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8 - 14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 - 29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30 - 49</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50+</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rarity  Rarity_Level\n",
       "0    1 - 3             1\n",
       "1    4 - 7             2\n",
       "2   8 - 14             3\n",
       "3  15 - 29             4\n",
       "4  30 - 49             5\n",
       "5      50+             6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Rarity': ['1 - 3', '4 - 7', '8 - 14', '15 - 29', '30 - 49', '50+'], 'Rarity_Level': [1,2,3,4,5,6]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few possible explanations for why this formula is usually exact, but not always. First, there could still be a missing term. However, if this is the case, then the term must have an extremely small coefficient since all of the errors are only off by $1$. Another argument against this is the lack of any true pattern in the mistakes. While this is not true proof, it does hint at a different problem. Second, and most likely, there could be a rounding error. The use of floor functions is thrown in to make this more accurate, but it's hard to know the correct place to put them. So far, this is the most accurate placement, but the rounding functions might not be floor functions and they could be placed differently. That would explain why the error is only $1$ off; it's a rounding error. Third, there could be a small mistake in the base stats. This is also not likely. I have only found one mistake in the data collected, and it resulted in a much larger error. Finally, the nature of Rarity_Level could be misunderstood. There's no reason that the gap between these needs to be the same. However, there's not any evidence to support that the levels should be different either.\n",
    "\n",
    "Due to the infrequency of errors, the fact that these are $1$-off errors, and the very human nature of the formula, I conclude that this is the underlying formula for determining offspring stats when the parent stats do not match. \n",
    "\n",
    "The obvious sequel to this project is to attempt to estimate the offspring stats when stat orders match and the random number generator is also used. Determining the effect and range of the random number generator will take lots of extra data collection, so there will likely be a large break before that is tackled."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
